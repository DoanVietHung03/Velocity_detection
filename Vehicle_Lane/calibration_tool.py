import cv2
import numpy as np
import pickle
import os

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# T√πy ch·ªânh session n·∫øu c·∫ßn
SESSION_DIR = os.path.join(PROJECT_ROOT, "Video_test", "BrnoCompSpeedSubset", "session_0")

VIDEO_PATH = os.path.join(SESSION_DIR, "video.avi")
DATA_PKL_PATH = os.path.join(SESSION_DIR, "gt_data.pkl")

# Bi·∫øn to√†n c·ª•c
clicked_points = []
frame_display = None
calibration_data = []

def load_ground_truth():
    global calibration_data
    print(f"Loading data from: {DATA_PKL_PATH}")
    try:
        with open(DATA_PKL_PATH, 'rb') as f:
            data = pickle.load(f, encoding='latin1')
            if 'distanceMeasurement' in data:
                for item in data['distanceMeasurement']:
                    p1 = np.array(item['p1']).flatten()[:2]
                    p2 = np.array(item['p2']).flatten()[:2]
                    dist = item['distance']
                    calibration_data.append((p1, p2, dist))
        print(f"--> ƒê√£ load {len(calibration_data)} ƒëo·∫°n th·∫≥ng m·∫´u.")
    except Exception as e:
        print(f"L·ªói ƒë·ªçc pickle: {e}")

def optimize_transform(source_points):
    """
    Ch·∫°y v√≤ng l·∫∑p ƒë·ªÉ t√¨m T·ª∑ l·ªá khung h√¨nh (Aspect Ratio) t·ªët nh·∫•t
    """
    src_pts = np.float32(source_points)
    target_w = 200 # Fix chi·ªÅu r·ªông
    
    best_error = 9999
    best_mpp = 0
    best_target_h = 200
    
    # Th·ª≠ c√°c t·ª∑ l·ªá chi·ªÅu cao kh√°c nhau t·ª´ ng·∫Øn ƒë·∫øn d√†i
    # Ratio = Height / Width. Th·ª≠ t·ª´ 0.5 (h√¨nh ch·ªØ nh·∫≠t n·∫±m ngang) ƒë·∫øn 20 (d·ªçc d√†i)
    print("ƒêang t·ªëi ∆∞u h√≥a t·ª∑ l·ªá...", end="")
    
    possible_ratios = np.linspace(0.5, 15.0, 150) # Qu√©t 150 m·ª©c t·ª∑ l·ªá
    
    for ratio in possible_ratios:
        target_h = int(target_w * ratio)
        
        dst_pts = np.float32([
            [0, 0], [target_w, 0],
            [target_w, target_h], [0, target_h]
        ])
        
        M = cv2.getPerspectiveTransform(src_pts, dst_pts)
        
        # T√≠nh to√°n sai s·ªë cho t·ª∑ l·ªá n√†y
        mpp_values = []
        for p1, p2, real_dist in calibration_data:
            pts_input = np.float32([p1, p2]).reshape(-1, 1, 2)
            pts_output = cv2.perspectiveTransform(pts_input, M).reshape(-1, 2)
            px_dist = np.linalg.norm(pts_output[0] - pts_output[1])
            
            if px_dist > 1:
                mpp_values.append(real_dist / px_dist)
        
        if not mpp_values: continue
        
        # ƒê·ªô l·ªách chu·∫©n (Standard Deviation) c√†ng th·∫•p nghƒ©a l√† MPP c√†ng ƒë·ªìng nh·∫•t
        # Gi·ªØa c√°c ƒëo·∫°n d·ªçc v√† ngang
        avg_mpp = np.mean(mpp_values)
        std_dev = np.std(mpp_values)
        
        # Metric ƒë√°nh gi√°: H·ªá s·ªë bi·∫øn thi√™n (CV)
        error_score = std_dev / avg_mpp
        
        if error_score < best_error:
            best_error = error_score
            best_mpp = avg_mpp
            best_target_h = target_h

    print(" Xong!")
    
    # T√≠nh l·∫°i sai s·ªë c·ª• th·ªÉ v·ªõi tham s·ªë t·ªët nh·∫•t v·ª´a t√¨m ƒë∆∞·ª£c
    final_dst_pts = np.float32([
        [0, 0], [target_w, 0],
        [target_w, best_target_h], [0, best_target_h]
    ])
    M_final = cv2.getPerspectiveTransform(src_pts, final_dst_pts)
    
    errors_percent = []
    for p1, p2, real_dist in calibration_data:
        pts_input = np.float32([p1, p2]).reshape(-1, 1, 2)
        pts_output = cv2.perspectiveTransform(pts_input, M_final).reshape(-1, 2)
        px_dist = np.linalg.norm(pts_output[0] - pts_output[1])
        
        est_dist = px_dist * best_mpp
        err = abs(est_dist - real_dist) / real_dist * 100
        errors_percent.append(err)
        
    avg_error_percent = np.mean(errors_percent)
    
    return avg_error_percent, best_mpp, best_target_h

def mouse_callback(event, x, y, flags, param):
    global clicked_points, frame_display
    
    if event == cv2.EVENT_LBUTTONDOWN:
        if len(clicked_points) < 4:
            clicked_points.append([x, y])
            cv2.circle(frame_display, (x, y), 5, (0, 0, 255), -1)
            cv2.imshow("CALIBRATION TOOL V2", frame_display)
            
            if len(clicked_points) == 4:
                cv2.polylines(frame_display, [np.array(clicked_points)], True, (0, 255, 0), 2)
                cv2.imshow("CALIBRATION TOOL V2", frame_display)
                
                print("\n--- K·∫æT QU·∫¢ ---")
                err, mpp, best_h = optimize_transform(clicked_points)
                print(f"‚úÖ Sai s·ªë sau khi t·ªëi ∆∞u: {err:.2f}%")
                print(f"üìè MPP chu·∫©n: {mpp:.5f}")
                print(f"üñºÔ∏è Target Height: {best_h} (Width=200)")
                
                if err < 5.0:
                    print("\n--- COPY V√ÄO CONFIG.PY ---")
                    print(f"SOURCE_POINTS = {clicked_points}")
                    print(f"METERS_PER_PIXEL = {mpp:.5f}")
                    print(f"TARGET_WIDTH = 200")
                    print(f"TARGET_HEIGHT = {best_h}")
                    print("--------------------------")
                else:
                    print("\n‚ö†Ô∏è Sai s·ªë v·∫´n h∆°i cao. H√£y th·ª≠ ch·ªçn 4 ƒëi·ªÉm kh√°c chu·∫©n h∆°n.")

def main():
    global frame_display, clicked_points
    
    load_ground_truth()
    
    cap = cv2.VideoCapture(VIDEO_PATH)
    ret, frame = cap.read()
    if not ret: return
    cap.release()
    
    frame_display = frame.copy()
    # V·∫Ω c√°c ƒëo·∫°n th·∫≥ng GT ƒë·ªÉ user d·ªÖ nh√¨n
    for p1, p2, dist in calibration_data:
        pt1 = (int(p1[0]), int(p1[1]))
        pt2 = (int(p2[0]), int(p2[1]))
        cv2.line(frame_display, pt1, pt2, (255, 255, 0), 2)

    print("\n--- H∆Ø·ªöNG D·∫™N V2 ---")
    print("Click 4 ƒëi·ªÉm bao quanh v√πng v·∫°ch k·∫ª ƒë∆∞·ªùng m√†u xanh l∆°.")
    print("Th·ª© t·ª±: Tr√°i-Tr√™n -> Ph·∫£i-Tr√™n -> Ph·∫£i-D∆∞·ªõi -> Tr√°i-D∆∞·ªõi")
    
    cv2.imshow("CALIBRATION TOOL V2", frame_display)
    cv2.setMouseCallback("CALIBRATION TOOL V2", mouse_callback)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()